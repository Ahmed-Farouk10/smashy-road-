# SmashyRoad: Reinforcement Learning Police Chase Game

A comprehensive reinforcement learning project implementing and comparing multiple RL algorithms in a 2D police chase game environment.

## ğŸ® Game Overview

**SmashyRoad** is a grid-based game where an agent must navigate from the starting position (2,2) to the goal (9,9) while:
- Avoiding a greedy police officer that chases the agent
- Managing step penalties and collision avoidance

### Game Mechanics
- **Grid Size**: 10Ã—10
- **Agent Start**: (2, 2)
- **Police Start**: (7, 7)
- **Goal Position**: (9, 9)
- **Fuel Bonus**: (5, 5) - worth +5 reward
- **Rewards**:
  - +100 for reaching goal
  - -100 for being caught
  - +5 for collecting fuel
  - -1 per step

## Firstly Review the report pdf 

## ğŸ¤– Implemented RL Algorithms

### 1. **Q-Learning**
- Value-based, off-policy learning algorithm
- Uses epsilon-greedy exploration strategy
- **Results**: 62% win rate on 300 test episodes

### 2. **Value Iteration**
- Dynamic programming approach
- Guaranteed optimal policy
- Computes value function for all states
- **Results**: 100% win rate on 300 test episodes â­

### 3. **Hybrid MCTS (Monte Carlo Tree Search)**
- Combines tree search with value iteration guidance
- Uses UCB1 (Upper Confidence Bound) for node selection
- Enhanced exploration with value-based policy priors
- **Results**: 65% win rate on 100 test episodes

### 4. **Rule-Based Agent**
- State-based heuristic approach
- Intelligent navigation toward goal
- Collision avoidance logic

## ğŸ“Š Performance Summary

| Model | Win Rate (Last 100) |
|-------|:------------------:|
| Q-Learning | 62% |
| Value Iteration | **100%** âœ“ |
| Hybrid MCTS | 65% |

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ env.py                      # Core game environment (SmashyRoadEnv)
â”œâ”€â”€ train.py                    # Training script for all agents
â”œâ”€â”€ q_learning.py               # Q-Learning implementation
â”œâ”€â”€ value_iteration.py          # Dynamic programming solver
â”œâ”€â”€ Montecarlo.py               # Pure MCTS implementation
â”œâ”€â”€ Montecarlohybird.py         # Hybrid MCTS implementation
â”œâ”€â”€ policy_gradient.py          # Policy gradient methods
â”œâ”€â”€ Rulebasedagent.py           # Rule-based heuristic agent
â”œâ”€â”€ play.py                     # Play with trained Q-Learning agent
â”œâ”€â”€ play_agents.py              # Demo all trained agents
â”œâ”€â”€ play_vi.py                  # Play with Value Iteration policy
â”œâ”€â”€ test_suite.py               # Unit tests
â”œâ”€â”€ test_policy.py              # Policy evaluation utilities
â”œâ”€â”€ utils.py                    # Helper functions
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ results/                    # Trained models and logs
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ q_table.npy         # Trained Q-table
â”‚   â”‚   â””â”€â”€ value_iteration_policy.json
â”‚   â”œâ”€â”€ logs/
â”‚   â”‚   â”œâ”€â”€ ql_rewards.npy
â”‚   â”‚   â”œâ”€â”€ ql_wins.npy
â”‚   â”‚   â”œâ”€â”€ mcts_rewards.npy
â”‚   â”‚   â””â”€â”€ mcts_wins.npy
â”‚   â””â”€â”€ reports/
â”‚       â””â”€â”€ summary.txt         # Training summary
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.7+
- pip or conda

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/smashyroad-rl.git
   cd smashyroad-rl
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Train all agents** (optional - pre-trained models included)
   ```bash
   python train.py
   ```

### Usage

#### Play with Q-Learning Agent
```bash
python play.py
```

#### Play with Value Iteration Agent
```bash
python play_vi.py
```

#### Demo All Agents
```bash
python play_agents.py
```

#### Run Tests
```bash
python test_suite.py
```

## ğŸ“‹ Requirements

- **pygame** â‰¥ 2.0.0 - Game rendering and visualization
- **numpy** â‰¥ 1.20.0 - Numerical computing
- **matplotlib** â‰¥ 3.3.0 - Data visualization

See `requirements.txt` for exact versions.

## ğŸ” Key Files Explained

### `env.py`
Defines the `SmashyRoadEnv` class - the core game environment with:
- State representation (agent pos, police pos)
- Action space (up, down, left, right)
- Reward function
- Pygame rendering

### `train.py`
Main training orchestration script:
- Trains Q-Learning on 30,000 episodes
- Trains Value Iteration (one-shot)
- Trains Hybrid MCTS on 1,000 episodes
- Saves models and generates summary report

### `q_learning.py`
Q-Learning implementation with:
- Epsilon-greedy exploration
- Learning rate (Î±) and discount factor (Î³)
- Experience replay-like updates

### `value_iteration.py`
Dynamic programming solver that:
- Generates all 10,000 possible states
- Iteratively improves value estimates
- Extracts optimal policy from value function

### `play_agents.py`
Interactive demo showing all agents in action with:
- Lightweight environment for fast simulation
- MCTS node with UCB1 exploration
- Side-by-side comparison

## ğŸ’¡ Algorithm Comparison

| Feature | Q-Learning | Value Iteration | Hybrid MCTS |
|---------|:----------:|:---------------:|:-----------:|
| **Learning Type** | Model-free | Model-based | Model-free |
| **Exploration** | Îµ-greedy | N/A (DP) | UCB1 |
| **Optimality** | Approximate | âœ“ Guaranteed | Approximate |
| **Scalability** | Good | Limited | Good |
| **Win Rate** | 62% | 100% | 65% |



## ğŸ“š Learning Resources

### Reinforcement Learning Concepts
- [OpenAI Gym Documentation](https://gym.openai.com/)
- [Sutton & Barto RL Book](http://incompleteideas.net/book/the-book-2nd.html)
- [Deep RL Hands-On](https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On)

### MCTS Resources
- [A Survey of Monte Carlo Tree Search Methods](https://ieee-explore.ieee.org/document/6564199)
- [Upper Confidence Bounds Applied to Trees](https://link.springer.com/article/10.1007/s10994-011-5258-6)

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ‘¨â€ğŸ’» Author

Created as an Applied Machine Learning (AML) project exploring practical implementations of classic and advanced RL algorithms.

## Demo link : https://drive.google.com/file/d/1r3V9bnvlBJsNOPHnavaQ1z0W1lW28Gdc/view?usp=sharing
